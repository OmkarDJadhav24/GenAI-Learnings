{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6838aa4-11cc-40c8-a787-940f88d2e51d",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e71b0b-edbd-4841-b2c1-4072b9c64985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae772b7-4572-400b-abd0-d50b2fe68a65",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aeeccb0-1880-4fc0-9a74-a9ada37697c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (25000, 2), 'test': (25000, 2), 'unsupervised': (50000, 2)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f46d48-c703-4e83-b104-2c32489546d9",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb7ae1a-d933-4ed4-8542-e0a0707e8643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5e53f8-5bd3-463b-84f3-b38bede44cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94ecd2-affb-4818-8eef-e2350f67c576",
   "metadata": {},
   "source": [
    "### Tokenize the dataset\n",
    "\n",
    "We'll use a pre-trained tokenizer(bert-base-uncased).\n",
    "\n",
    "`bert-base-uncased` refers to a lowercase version of BERT (i.e., it converts all text to lowercase and doesnâ€™t distinguish between capital letters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd358dd-009f-440e-b574-014d26b06050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af7e5a2bf7e49e997d16dd1aabc8320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"],\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    max_length=256)\n",
    "    \n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db3325c-3f73-4a42-b678-da311a2bc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'input_ids' : (the token IDs),\n",
    "# 'attention_mask' : (indicates which tokens are real vs. padding)\n",
    "#  token_type_ids: Used in tasks like QA\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed4f85-8c91-4f5d-a97f-e1ad0c8737b1",
   "metadata": {},
   "source": [
    "### Format for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70ae7fd-65ec-47ee-b8ad-cd739d18d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b2c7c8-2af0-42b4-a754-2e0ba79ef7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(0),\n",
       " 'input_ids': tensor([  101,  1000,  1045,  2572,  8025,  1024,  3756,  1000,  2003,  1037,\n",
       "         15544, 19307,  1998,  3653,  6528, 20771, 19986,  8632,  1012,  2009,\n",
       "          2987,  1005,  1056,  3043,  2054,  2028,  1005,  1055,  2576,  5328,\n",
       "          2024,  2138,  2023,  2143,  2064,  6684,  2022,  2579,  5667,  2006,\n",
       "          2151,  2504,  1012,  2004,  2005,  1996,  4366,  2008, 19124,  3287,\n",
       "         16371, 25469,  2003,  2019,  6882, 13316,  1011,  2459,  1010,  2008,\n",
       "          3475,  1005,  1056,  2995,  1012,  1045,  1005,  2310,  2464,  1054,\n",
       "          1011,  6758,  3152,  2007,  3287, 16371, 25469,  1012,  4379,  1010,\n",
       "          2027,  2069,  3749,  2070, 25085,  5328,  1010,  2021,  2073,  2024,\n",
       "          1996,  1054,  1011,  6758,  3152,  2007, 21226, 24728, 22144,  2015,\n",
       "          1998, 20916,  4691,  6845,  2401,  1029,  7880,  1010,  2138,  2027,\n",
       "          2123,  1005,  1056,  4839,  1012,  1996,  2168,  3632,  2005,  2216,\n",
       "         10231,  7685,  5830,  3065,  1024,  8040,  7317,  5063,  2015, 11820,\n",
       "          1999,  1996,  9478,  2021,  2025,  1037, 17962, 21239,  1999,  4356,\n",
       "          1012,  1998,  2216,  3653,  6528, 20771, 10271,  5691,  2066,  1996,\n",
       "          2829, 16291,  1010,  1999,  2029,  2057,  1005,  2128,  5845,  2000,\n",
       "          1996,  2609,  1997,  6320, 25624,  1005,  1055, 17061,  3779,  1010,\n",
       "          2021,  2025,  1037,  7637,  1997,  5061,  5710,  2006,  9318,  7367,\n",
       "          5737, 19393,  1012,  2077,  6933,  1006,  2030, 20242,  1007,  1000,\n",
       "          3313,  1011,  3115,  1000,  1999,  5609,  1997, 16371, 25469,  1010,\n",
       "          1996, 10597, 27885,  5809,  2063,  2323,  2202,  2046,  4070,  2028,\n",
       "         14477,  6767,  8524,  6321,  5793, 28141,  4489,  2090,  2273,  1998,\n",
       "          2308,  1024,  2045,  2024,  2053,  8991, 18400,  2015,  2006,  4653,\n",
       "          2043, 19910,  3544, 15287,  1010,  1998,  1996,  2168,  3685,  2022,\n",
       "          2056,  2005,  1037,  2158,  1012,  1999,  2755,  1010,  2017,  3227,\n",
       "          2180,  1005,  1056,  2156,  2931,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872918b-2419-4336-a2c3-f6b01924b882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
